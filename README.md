## <center>2 Approach

### 2.1 Model Architecture

> 在本节中将概述整体创新做法，在2.1.x中详细展开

* **旋转位置嵌入**（1D RoPE）改为**多模态旋转位置嵌入**（MRoPE）
  * 旋转位置嵌入即在复数域中进行旋转来编码位置信息，为模型提供每个token的位置信息
  * 多模态旋转位置词嵌入将位置信息分解为***时间Temporal、高度Height、宽度Width***，对于不同类型输入三个分量使用方式不同。例如：对于视频即为宽、高与帧序列，图像与文本输入同理
* 采用重新设计的**ViT**架构
  * 结合2D RoPE与窗口注意力以支持图像原生分辨率输入
  * 图像高宽resize为28的倍数，并切割为`14*14`的patch
* 压缩特征序列再输入LLM
  * 不直接用ViT提取的patch，而是将相邻的四个patch分组的特征连接，通过MLP投影到LLM中文本嵌入对齐的维度中

#### 2.1.1 Fast and Efficient Vision Encoder快速高效的视觉编码器

* 仅有四层采用了完全自注意力机制，其余都是窗口注意力机制，以降低复杂度；窗口注意力中最大窗口为`112*112`，更小的区域不进行填充，以避免分辨率差异导致的计算负载不均衡
* 位置编码上，`14*14`大小的patch作为输入块，并在视频处理上将**两个连续帧**组合到一起，减少输入词元数
* 为简化网络结构，采用`RMSNorm`归一化，`SwiGLU`作为激活函数，提高计算效率
* 训练过程中，图像根据宽高比**随即采样**，泛化不同分辨率输入

#### 2.1.2 Native Dynamic Resolution and Frame Rate原生动态分辨率和帧率

* 直接使用输入图像的尺寸来表示边界框、点等空间信息，提高处理不同分辨率图像的能力
* 视频输入采用`MPoPE ID`直接与帧率和时间戳对齐，让模型直接用这个理解时间节奏

#### 2.1.3 Multimodal Rotary Position Embedding Aligned to Absolute Time与绝对时间对齐的多模态旋转位置嵌入

* Qwen2-VL中将时间ID与输入帧数绑定，没有考虑视频速度等问题，故Qwen2.5-VL中将MRoPE的时间分量与绝对时间对齐

### 2.2 Pre-Training

> 本节中主要讲述与训练数据集的构建与训练的整个流程

#### 2.2.1 Pre-Training Data训练数据

* 现阶段图像-文本交错数据存在噪声等的问题，为此Qwen-VL开发了一套数据评分与清洗流程，首先进行数据清洗，然后使用内部模型进行评分。评分标准包括：纯文本质量；图文相关性；信息互补性；信息密度平衡。
* 数据集方面
  * 为提高基础能力的通用性，开发了一个综合数据集，包括边界框和带有引用表达式的点
  * 为提升模型开放词汇检测的能力，将训练数据集扩展到超过10000个对象类别
* 后面是一堆同样的数据集的改进描述，不加赘述

#### 2.2.2 Training Recipe训练策略

> 训练分为三个阶段

* 用DataComp等数据集从头训练一个ViT模型初始化视觉编码器，再用Qwen2.5预训练大语言模型初始化LLM组件
* 第一阶段中，仅训练ViT，提高他与语言模型的匹配度
* 第二阶段中，训练所有模型参数
* 第三阶段中，进一步增加序列长度
* 训练优化策略：
  * 窗口注意力减少视觉编码器的计算需求
  * 数据统一打包成固定长度的序列，并在不同训练阶段序列长度不同。一二阶段长度8192，三阶段32768
